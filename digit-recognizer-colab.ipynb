{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF-2i5GRwOe1",
    "colab_type": "text"
   },
   "source": [
    "Digit recognition is not something that difficult or advanced. It is kind of \"Hello world!\" program - not that cool, but you start exactly here. So I decided to share my work and at the same time refresh the knowledge - it's being a long ago I played with images.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlsMEe_Tvuki",
    "colab_type": "text"
   },
   "source": [
    "We start with importing all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "SkDE4JL6v0bH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEhh9O7WxSz7",
    "colab_type": "text"
   },
   "source": [
    "MNIST dataset, which contains 20 thousand hand-written digits is a \"Hello World\" dataset for this task, it is already preloaded in Colaboratory (cloud-based Python notebooks, fantastic thing), so we will use it. No need to invent a wheel here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "puODnyYTwdQQ",
    "colab_type": "code",
    "outputId": "e035f475-cc5e-48ce-e83d-1c2d16dddfda",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54217342261E12,
     "user_tz": -60.0,
     "elapsed": 2670.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    6    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    5    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    7    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    9    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    5    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('sample_data/mnist_train_small.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LVQ7iNr-wg6c",
    "colab_type": "code",
    "outputId": "c414da9a-207a-4807-f00e-0125340b44c6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173423334E12,
     "user_tz": -60.0,
     "elapsed": 653.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtlLxPZhyPic",
    "colab_type": "text"
   },
   "source": [
    "As we can see from the head() method, first column in dataset contains labels and the rest pixels of the image 28x28 - that is why we have 784 columns more. \n",
    "It is also useful to check the length of the dataset each time after some modification to make sure we did everything correct.\n",
    "\n",
    "---\n",
    "\n",
    "Next, let's visualize our pixels and watch the images we have. We use randint() to select random image every time we run the code below. Also we have to transform our pixels to numpy array (now its' type is Series) and reshape it to the size 28x28 to be able to plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pNIgMOb0wrbU",
    "colab_type": "code",
    "outputId": "18c8779c-9956-46d3-ec5a-fc7ee727f019",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173424318E12,
     "user_tz": -60.0,
     "elapsed": 733.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9ac6fda20>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6FICBl1KwKBLCRh0KYH/B99Uk+OInbjBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9ac761080>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix = random.randint(0, len(df)-1)\n",
    "label, pixels = df.loc[ix][0], df.loc[ix][1:]\n",
    "img = np.array(pixels).reshape((28,28))\n",
    "print('label: ' + str(label))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPS_oOjU00r7",
    "colab_type": "text"
   },
   "source": [
    "Now, to make our life little bit easier we will transform our dataframe to have only two columns - label and image, where image is a numpy array of pixels. Also we will reduce the size of dataframe for faster computation (first we want to make sure everything works and then we start playing with model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dCzMb3QZw4Ew",
    "colab_type": "code",
    "outputId": "211f5b3f-eca1-4d38-9828-e951ef4b8829",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173427851E12,
     "user_tz": -60.0,
     "elapsed": 3469.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 img  label\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      6\n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      5\n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      7\n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      9\n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      5"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming df for easier manipulation\n",
    "labels, imgs = [], []\n",
    "for index, row in df.iterrows():\n",
    "    label, pixels = row[0], row[1:]\n",
    "    img = np.array(pixels)\n",
    "    labels.append(label)\n",
    "    imgs.append(img)\n",
    "df2 = pd.DataFrame({'label': labels, 'img': imgs})\n",
    "df2 = df2[:1000]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "srN0F_F1xTYG",
    "colab_type": "code",
    "outputId": "716e9c93-a9e7-486d-a76e-427e6bb1c6e0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54217342876E12,
     "user_tz": -60.0,
     "elapsed": 859.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9a9b997f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff9ac6c8978>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking images using new df structure\n",
    "ix = random.randint(0, len(df2)-1)\n",
    "img = df2.loc[ix].img.reshape((28,28))\n",
    "label = df2.loc[ix].label\n",
    "print('label: ' + str(label))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sz3Y_S6x2GdE",
    "colab_type": "text"
   },
   "source": [
    "When we have our data prepared, we want to split it into 2 datasets: one to traing our model and another to test it's performance. And the best way to do that is using *sklearn*. We set up a *test_size=0.2* which is standard value for this operation (usually for test we leave 20-30% of data), which means that for training remains 80%. It is also a good practice to set *shuffle=True* as some datasets might have ordered data, so the model will learn to recognize 0s and 1s, but won't have any idea that 8 exists for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HsHpeiGBx4B4",
    "colab_type": "code",
    "outputId": "0542c49d-8c0a-4705-f172-d1ac14c67100",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173429476E12,
     "user_tz": -60.0,
     "elapsed": 658.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OXsT-FyOyDpD",
    "colab_type": "code",
    "outputId": "c1871724-7672-4555-e24d-489c7359308c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173430313E12,
     "user_tz": -60.0,
     "elapsed": 525.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   img  label\n",
       "825  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      0\n",
       "305  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      7\n",
       "189  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      3\n",
       "397  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      7\n",
       "70   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      8"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lV3qNa3r34kc",
    "colab_type": "text"
   },
   "source": [
    "We check the length, the head of datasets - all good, we can start building our model. For this we will need to install *pytorch*. If we go to \"Code snippets\" and start typing there *'pyt'* it will show us \"Install [pytorch]\", so we can insert it into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "EhL8ddREyHu_",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yAFZHCSnyRhu",
    "colab_type": "code",
    "outputId": "549642b8-057f-4a5c-c277-3e57052cd8ae",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173435871E12,
     "user_tz": -60.0,
     "elapsed": 855.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# importing torch and setting up the device\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRRcleLq5pPV",
    "colab_type": "text"
   },
   "source": [
    "Next, we have to transform our data into pytorch Dataset. `torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:\n",
    "*   `__len__ `so that `len(dataset)` returns the size of the dataset.\n",
    "*   `__getitem__` to support the indexing such that `dataset[i]` can be used to get its sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YYxuxnOnyYf2",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# create torch dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "  def __init__(self, imgs, labels):\n",
    "    super(MNISTDataset, self).__init__()\n",
    "    self.imgs = imgs\n",
    "    self.labels = labels\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.imgs)\n",
    "  \n",
    "  def __getitem__(self, ix):\n",
    "    img = self.imgs[ix]\n",
    "    label = self.labels[ix]\n",
    "    return torch.from_numpy(img).float(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Mi_j-gAZy3mn",
    "colab_type": "code",
    "outputId": "aa6fc61d-8975-401b-eb75-a09695062110",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173437387E12,
     "user_tz": -60.0,
     "elapsed": 498.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = {\n",
    "    'train': MNISTDataset(train_df.img.values, train_df.label.values),\n",
    "    'test': MNISTDataset(test_df.img.values, test_df.label.values)\n",
    "} \n",
    "\n",
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KT6VmXA-zWPF",
    "colab_type": "code",
    "outputId": "6b228c2f-2d35-4078-f480-d5ec72659a21",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173438369E12,
     "user_tz": -60.0,
     "elapsed": 751.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784]) torch.float32\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff99eeeed30>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlzJg0KUMGHQpA/8P6QUqO/LFZWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff99ef2a5c0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# againg checking image, now based on torch dataset\n",
    "ix = random.randint(0, len(dataset['train'])-1)\n",
    "img, label = dataset['train'][ix]\n",
    "print(img.shape, img.dtype)\n",
    "print(label)\n",
    "plt.imshow(img.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAvTDevk672y",
    "colab_type": "text"
   },
   "source": [
    "The beauty of pytorch is its simplicity in defining the model. We define our layer with inputs and outputs, we add some batch normalization to improve our model (It is a technique to provide any layer in a neural network with inputs that are zero mean/unit variance) and activation function, in this case ReLU.\n",
    "\n",
    "For the first input we have 784 neurons (one neuron per each pixel) and 512 for output (this one is almost random - I tried few different values and this one performed pretty well, so I left it). Next layer will have 512 inputs (input_layer[n+1] == output_layer[n]) and 256 for output, next 256 inputs and 128 outputs and the last one - 128 inputs and 10 for output (each neuron represents one of 10 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Kuzz2YBJzn9g",
    "colab_type": "code",
    "outputId": "198289c6-89b6-47c5-a7a8-b85e87c8530e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173439056E12,
     "user_tz": -60.0,
     "elapsed": 654.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323.0
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "import torch.nn as nn\n",
    "\n",
    "def block(in_f, out_f):\n",
    "  return nn.Sequential(\n",
    "      nn.Linear(in_f, out_f),\n",
    "      nn.BatchNorm1d(out_f),\n",
    "      nn.ReLU(inplace=True),\n",
    "      #nn.Dropout(),\n",
    "  )\n",
    "\n",
    "model = nn.Sequential(\n",
    "  block(784,512),\n",
    "  block(512,256),\n",
    "  block(256,128),\n",
    "  nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HX-GpHv_MvU",
    "colab_type": "text"
   },
   "source": [
    "Now we need to create few additional parameters for our model:\n",
    "\n",
    "*   criterion - to calculate loss function, in our case [CrossEntropyLoss](https://https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss)\n",
    "*   optimizer - to set up learning rate\n",
    "*   scheduler - to update learning rate if model doesn't improve with time (quite powerful technique, allows us to tweak the system on the go)\n",
    "*   dataloader - class for pytorch that provides single- or multi-process iterators over the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "hRewbku5z1AW",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', factor=0.1, patience=3, min_lr=0.0001, verbose=True)\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=32, shuffle=True, num_workers=4),\n",
    "    'test': DataLoader(dataset['test'], batch_size=32, shuffle=False, num_workers=4),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YV1O_eHVhajt",
    "colab_type": "text"
   },
   "source": [
    "With all above we can start training and evaluating our model. Although we define 100 epochs, it is also useful to stop the loop if model doesn't improve with time. Here we have set up `early_stop = 10`, so if model doesn't change for 10 epochs in a row we will stop the training process.\n",
    "\n",
    "Training process: we iterate through our train data by assigning each image and label to a device defined previously, we give our model an image and it tries to find the correct class (`preds`), we clear all gradients (`zero_grad()`) and calculate the loss function and the gradient (`loss`), perform an optimizer step and append new value to a `total_loss` array.\n",
    "\n",
    "Testing process: we iterate through the test data, make predictions, calculate the loss and accuracy of the model. In `torch.max()` we are looking for an index of the maximum value as it will represent the class of a digit and in our case it will match labels. Then by comparing labels and predictions we calculate the accuracy of our model.\n",
    "\n",
    "Every time we find the best model we save it and if we hit the `early_stop` we exit and report the results. Usually it won't need all those 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "dIdoHrWQ0E6C",
    "colab_type": "code",
    "outputId": "606d9e0c-6a7a-47e9-cba3-c6b07c139f44",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.54217346289E12,
     "user_tz": -60.0,
     "elapsed": 22873.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2448.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.24it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 61.19it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 1, Training loss: 1.287729, Val loss: 1.297057, Val acc: 0.690000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 50.73it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 53.33it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 2, Training loss: 0.714153, Val loss: 1.025788, Val acc: 0.770000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.65it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 48.32it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 3, Training loss: 0.526018, Val loss: 0.475901, Val acc: 0.855000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.35it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 51.34it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 4, Training loss: 0.390981, Val loss: 0.584928, Val acc: 0.850000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 52.03it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 60.43it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 5, Training loss: 0.299076, Val loss: 0.409660, Val acc: 0.890000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 52.62it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 57.51it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 6, Training loss: 0.282667, Val loss: 0.569010, Val acc: 0.890000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 50.77it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 49.89it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 7, Training loss: 0.368993, Val loss: 0.546251, Val acc: 0.870000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 52.36it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 47.32it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 8, Training loss: 0.293367, Val loss: 0.588393, Val acc: 0.830000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 49.85it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 57.07it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 9, Training loss: 0.176275, Val loss: 0.452349, Val acc: 0.895000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.08it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 61.36it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 10, Training loss: 0.190740, Val loss: 0.749223, Val acc: 0.855000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 46.52it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 48.19it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 11, Training loss: 0.231334, Val loss: 0.710024, Val acc: 0.845000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 47.92it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 12, Training loss: 0.176967, Val loss: 0.570731, Val acc: 0.840000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.76it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 67.64it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-02.\n",
      "\n",
      " Epoch 13, Training loss: 0.195777, Val loss: 0.656643, Val acc: 0.865000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.06it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 52.98it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 14, Training loss: 0.085389, Val loss: 0.498354, Val acc: 0.875000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 47.41it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 50.36it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 15, Training loss: 0.031412, Val loss: 0.436563, Val acc: 0.890000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 48.63it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 55.56it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 16, Training loss: 0.029874, Val loss: 0.388386, Val acc: 0.900000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 52.98it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 54.83it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 17, Training loss: 0.049520, Val loss: 0.423354, Val acc: 0.900000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 50.19it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 57.25it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 18, Training loss: 0.023294, Val loss: 0.386265, Val acc: 0.900000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 53.67it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 51.05it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 19, Training loss: 0.022117, Val loss: 0.393941, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 53.84it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 55.80it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 20, Training loss: 0.023545, Val loss: 0.388233, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.04it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 63.19it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model ! saved.\n",
      "\n",
      " Epoch 21, Training loss: 0.005979, Val loss: 0.374836, Val acc: 0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 33.37it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 58.39it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 22, Training loss: 0.013613, Val loss: 0.374461, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.05it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 72.11it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 23, Training loss: 0.005479, Val loss: 0.358950, Val acc: 0.895000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 51.37it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 66.87it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 24, Training loss: 0.015302, Val loss: 0.384199, Val acc: 0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 49.19it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 68.84it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      " Epoch 25, Training loss: 0.002659, Val loss: 0.428535, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 46.21it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 66.47it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 26, Training loss: 0.007188, Val loss: 0.429362, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 41.78it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 48.38it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 27, Training loss: 0.023056, Val loss: 0.421917, Val acc: 0.905000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 29.88it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 49.11it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 28, Training loss: 0.011646, Val loss: 0.442238, Val acc: 0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 24.24it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 52.27it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      " Epoch 29, Training loss: 0.010954, Val loss: 0.404354, Val acc: 0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 22.26it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 64.31it/s]\n",
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 30, Training loss: 0.015759, Val loss: 0.397337, Val acc: 0.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 22.10it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 73.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best model with acc: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "best_acc, stop, early_stop = 0, 0, 10\n",
    "for e in range(100):\n",
    "    \n",
    "  model.train()\n",
    "  total_loss = []\n",
    "  for imgs, labels in tqdm(dataloader['train']):\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    preds = model(imgs)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss.append(loss.data)\n",
    "    \n",
    "  model.eval()\n",
    "  val_loss, acc = [], 0.\n",
    "  with torch.no_grad():\n",
    "    for imgs, labels in tqdm(dataloader['test']):\n",
    "      imgs, labels = imgs.to(device), labels.to(device)\n",
    "      preds = model(imgs)\n",
    "      loss = criterion(preds, labels)\n",
    "      val_loss.append(loss.data)\n",
    "      _, preds = torch.max(preds, 1)\n",
    "      acc += (preds == labels).sum().item()\n",
    "      \n",
    "  acc /= len(dataset['test'])\n",
    "  if acc > best_acc:\n",
    "    print('\\n Best model ! saved.')\n",
    "    torch.save(model.state_dict(), 'best_model.pt')\n",
    "    best_acc = acc\n",
    "    stop = -1\n",
    "  \n",
    "  stop += 1\n",
    "  if stop >= early_stop:\n",
    "    break\n",
    "    \n",
    "  scheduler.step(acc)\n",
    "    \n",
    "  print('\\n Epoch {}, Training loss: {:4f}, Val loss: {:4f}, Val acc: {:4f}'.format(\n",
    "      e+1, np.array(total_loss).mean(), np.array(val_loss).mean(), acc))\n",
    "  \n",
    "print('\\n Best model with acc: {}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53ZptqytqqWh",
    "colab_type": "text"
   },
   "source": [
    "When we find our best model and save it, we can play with it by feeding it with new data and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1H_ytEgU0UWe",
    "colab_type": "code",
    "outputId": "85b13eb7-7293-4805-f792-3d0387370fd4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.542173463762E12,
     "user_tz": -60.0,
     "elapsed": 789.0,
     "user": {
      "displayName": "Serhii Lehkyi",
      "photoUrl": "https://lh3.googleusercontent.com/-qassuiEDJBU/AAAAAAAAAAI/AAAAAAAALJ8/PaeC0MtgnoQ/s64/photo.jpg",
      "userId": "14713728991309101865"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 5, Prediction: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff9a9ced748>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKpOfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff99ef07748>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "ix = random.randint(0, len(dataset['test'])-1)\n",
    "img, label = dataset['test'][ix]\n",
    "pred = model(img.unsqueeze(0).to(device)).cpu()\n",
    "pred_label = torch.argmax(pred)\n",
    "print('Ground Truth: {}, Prediction: {}'.format(label, pred_label))\n",
    "plt.imshow(img.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFy9h-40rU9v",
    "colab_type": "text"
   },
   "source": [
    "Like it was said in the beginning it is a \"Hello World\" for the image recognition, we didn't use convolutional neural network which is normally used in tasks like this, just entry level to understand the flow. I don't usually work with images, so if there are some mistakes, please let me know. It was a nice refresher for me, hopefully it helped someone else."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "digit-recognizer-colab.ipynb",
   "version": "0.3.2",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
